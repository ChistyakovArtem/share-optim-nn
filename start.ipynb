{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78180fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tech_core.feature_pipeline import FeaturesPipeline\n",
    "\n",
    "path_to_data = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363c76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FeaturesPipeline(\n",
    "    path_to_data=path_to_data,\n",
    "    padding=0,\n",
    "    chunk_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce922e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "cmf_dim = asset_dim = num_assets = None\n",
    "for common_feats, asset_feats, fut_ret in tqdm(reader):\n",
    "    cmf_dim = common_feats.shape[1]\n",
    "    asset_dim = asset_feats.shape[2]\n",
    "    num_assets = asset_feats.shape[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tech_core.losses import StreamingSharpeLoss\n",
    "from tech_core.nn_builder import SimplePortfolioAllocator, DeepPortfolioAllocator\n",
    "import torch\n",
    "\n",
    "model = SimplePortfolioAllocator(\n",
    "    cmf_dim=cmf_dim,\n",
    "    asset_dim=asset_dim,\n",
    "    num_assets=num_assets,\n",
    "    hidden_cmf=64,\n",
    "    hidden_asset=32,\n",
    "    head_hidden=16\n",
    ")\n",
    "\n",
    "# Big NN\n",
    "# Sharpe Ratio (MSE-guided) for the epoch: 0.0106\n",
    "# Total MSE loss for the epoch: 0.0000007199\n",
    "# Pnl : 0.2\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 100 # Количество эпох обучения\n",
    "fees = 1.5e-4\n",
    "for epoch in range(num_epochs):\n",
    "    loss_fn = StreamingSharpeLoss(fee=fees)\n",
    "    loss_fn.reset()\n",
    "    reader = FeaturesPipeline(path_to_data, padding=35, chunk_size=1000)\n",
    "\n",
    "    for common_feats, asset_feats, fut_ret in tqdm(reader, desc=f\"Epoch {epoch+1}\"):\n",
    "\n",
    "        # Перевод в тензоры\n",
    "        common_feats = torch.tensor(common_feats.values, dtype=torch.float32).to(device)       # (T, d_common)\n",
    "        asset_feats  = torch.tensor(asset_feats,         dtype=torch.float32).to(device)       # (T, n_assets, d_asset)\n",
    "        fut_ret      = torch.tensor(fut_ret.values,      dtype=torch.float32).to(device)       # (T, n_assets)\n",
    "\n",
    "        if len(common_feats) != 1000:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Вычисляем веса\n",
    "        weights = model(common_feats, asset_feats)  # (T, n_assets)\n",
    "        # Обновляем метрику\n",
    "        loss_value = loss_fn.forward(\n",
    "            weights=weights,\n",
    "            returns=fut_ret\n",
    "        )\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_fn.plot_whole_epoch_loss()  # Выводим Sharpe Ratio за эпоху"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c78fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
